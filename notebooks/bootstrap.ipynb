{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Import Libraries and Initial Settings"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "source": [
    "CUDA = 1\n",
    "RANDOM_STATE = 2021\n",
    "device = torch.device(f'cuda:{CUDA}' if torch.cuda.is_available() else 'cpu')\n",
    "torch.manual_seed(RANDOM_STATE)\n",
    "np.random.seed(RANDOM_STATE)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 2,
   "outputs": []
  },
  {
   "source": [
    "# Load data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '../data'\n",
    "train_err = pd.read_csv(os.path.join(PATH, 'train_err_data.csv'))\n",
    "train_problem = pd.read_csv(os.path.join(PATH, 'train_problem_data.csv'))\n",
    "test_err = pd.read_csv(os.path.join(PATH, 'test_err_data.csv'))"
   ]
  },
  {
   "source": [
    "# Define Dataset and Model Class"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data):\n",
    "        super(Dataset, self).__init__()\n",
    "        self.data = data\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        input = torch.Tensor(self.data[index, :-1])\n",
    "        label = torch.Tensor(self.data[index, -1:])\n",
    "        return input, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_num):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.dense = nn.Sequential(\n",
    "            nn.Linear(input_num, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dense(x)\n",
    "        return x"
   ]
  },
  {
   "source": [
    "# Data Prepration"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data(err, problem, users, scaler=None, time_before=False):\n",
    "    global TOTAL_ERR_NUM, INPUT_NUM, used_code_dict\n",
    "\n",
    "    data = np.zeros((len(users), INPUT_NUM + 1))\n",
    "    user2idx = {user: idx for idx, user in enumerate(users)}\n",
    "\n",
    "    if time_before:\n",
    "        alive_func = lambda row: row['time'] <= init_report_time[row['user_id']] \\\n",
    "                                 if row['user_id'] in init_report_time \\\n",
    "                                 else True\n",
    "        alive = err.apply(alive_func, axis=1)\n",
    "        err = err[alive]\n",
    "\n",
    "    user_err = err[['user_id', 'errtype']].values\n",
    "    for user, errtype in tqdm(user_err):\n",
    "        idx = user2idx[user]\n",
    "        data[idx, errtype] = 1.  # true false\n",
    "        # data[idx, 0] += 1  # total_errs\n",
    "\n",
    "    code_start_index = 1 + TOTAL_ERR_NUM\n",
    "    user_id = err['user_id'].values\n",
    "    errcode = err['errcode'].values\n",
    "    for user, errcode in tqdm(zip(user_id, errcode)):\n",
    "        if errcode in used_code_dict:\n",
    "            col = code_start_index + used_code_dict[errcode]\n",
    "            data[user2idx[user], col] = 1.  # true false\n",
    "\n",
    "    # Standard-scale\n",
    "    scaler = None\n",
    "    # if scaler is None:\n",
    "    #     scaler = StandardScaler()\n",
    "    #     scaler.fit(data[:, :-1])\n",
    "    # data[:, :-1] = scaler.transform(data[:, :-1])\n",
    "\n",
    "    if problem is not None:  # if train data\n",
    "        true_targets = [user2idx[user] for user in problem['user_id']]\n",
    "        data[true_targets, -1] = 1.\n",
    "\n",
    "    return data, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "# of inputs: 85\n",
      "100%|██████████| 16554663/16554663 [00:15<00:00, 1053377.46it/s]\n",
      "16554663it [00:07, 2089269.97it/s]\n",
      "100%|██████████| 16532648/16532648 [00:16<00:00, 1031081.76it/s]\n",
      "16532648it [00:07, 2130373.35it/s]\n"
     ]
    }
   ],
   "source": [
    "# constants for data preprocess\n",
    "TOTAL_ERR_NUM = 42\n",
    "USED_CODES = ['5', '6', 'V-21008', 'terminate by peer user', 'H-51042', '4',\n",
    "              'connection fail to establish', '82', '13', '14', '83', '99', '3', '88',\n",
    "              'connection timeout', '100', 'connectionterminated by local host', '91',\n",
    "              'UNKNOWN', '95', '87', '94', '78', '89', '90', '81', '86', 'active',\n",
    "              '85', '84', '2', 'NFANDROID2', 'S-61001', '1', '80', '79', 'B-A8002',\n",
    "              'standby', '8.0', '0', 'S-65002', 'Q-64002']\n",
    "INPUT_NUM = 1 + TOTAL_ERR_NUM + len(USED_CODES)  # total_errs + ...\n",
    "tv_users   = np.array(range(10000, 25000))\n",
    "test_users = np.array(range(30000, 44999))\n",
    "print('# of inputs:', INPUT_NUM)\n",
    "\n",
    "# get hashes such as used_code_dict, init_report_time\n",
    "used_code_dict = {code: i for i, code in enumerate(USED_CODES)}\n",
    "init_report_time = {}\n",
    "for _, row in train_problem.iterrows():\n",
    "    if row['user_id'] not in init_report_time:\n",
    "        init_report_time[row['user_id']] = row['time']\n",
    "    else:\n",
    "        if init_report_time[row['user_id']] > row['time']:  # save earlier time\n",
    "            init_report_time[row['user_id']] = row['time']\n",
    "\n",
    "# get a scaler and make test data\n",
    "_,   scaler = make_data(train_err, train_problem, tv_users)\n",
    "testdata, _ = make_data(test_err , None         , test_users , scaler)"
   ]
  },
  {
   "source": [
    "# Training"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# hyperparameters for learning\n",
    "LR = 1e-3\n",
    "BATCH_SIZE = 1024\n",
    "MAX_EPOCHS = 100\n",
    "PATIENCE = 15\n",
    "\n",
    "k_fold = KFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "best_aucs = [0.] * k_fold.get_n_splits()\n",
    "\n",
    "for i_fold, (train_idx, valid_idx) in enumerate(k_fold.split(tv_users)):\n",
    "    print(f'Fold {i_fold} started!')\n",
    "\n",
    "    train_users = tv_users[train_idx]\n",
    "    valid_users = tv_users[valid_idx]\n",
    "\n",
    "    te = train_err[train_err['user_id'].isin(train_users)]  # 오래 걸림\n",
    "    ve = train_err[train_err['user_id'].isin(valid_users)]  # 오래 걸림\n",
    "    tp = train_problem[train_problem['user_id'].isin(train_users)]\n",
    "    vp = train_problem[train_problem['user_id'].isin(valid_users)]\n",
    "\n",
    "    traindata, _ = make_data(te, tp, train_users, scaler, True)\n",
    "    validdata, _ = make_data(ve, vp, valid_users, scaler)\n",
    "\n",
    "    trainset = Dataset(traindata)\n",
    "    validset = Dataset(validdata)\n",
    "\n",
    "    trainloader = DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    validloader = DataLoader(validset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    net = Net(INPUT_NUM).to(device)\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=LR)\n",
    "    criterion = nn.BCELoss()\n",
    "\n",
    "    stop_cnt = 0\n",
    "\n",
    "    # loop over the dataset multiple times\n",
    "    for epoch in range(1, MAX_EPOCHS + 1):\n",
    "        print(f'Epoch {epoch} ', end='\\t')\n",
    "\n",
    "        # Training\n",
    "        net.train()\n",
    "        running_loss = 0.0\n",
    "        saved_outputs = []\n",
    "        saved_labels = []\n",
    "\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss  += loss.item() * len(outputs)\n",
    "            saved_outputs += outputs.squeeze()        .tolist()\n",
    "            saved_labels  += (labels.squeeze() >= 0.5).tolist()\n",
    "\n",
    "        running_loss /= len(trainloader.dataset)\n",
    "        auc = roc_auc_score(saved_labels, saved_outputs)\n",
    "\n",
    "        print(f'train loss={running_loss:.3f} \\t'\n",
    "              f'train auc={ auc         :.3f} \\t', end='')\n",
    "\n",
    "        # Validation\n",
    "        net.eval()\n",
    "        running_loss = 0.0\n",
    "        saved_outputs = []\n",
    "        saved_labels = []\n",
    "\n",
    "        for i, data in enumerate(validloader, 0):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss  += loss.item() * len(outputs)\n",
    "            saved_outputs += outputs.squeeze()        .tolist()\n",
    "            saved_labels  += (labels.squeeze() >= 0.5).tolist()\n",
    "\n",
    "        running_loss /= len(validloader.dataset)\n",
    "        auc = roc_auc_score(saved_labels, saved_outputs)\n",
    "\n",
    "        print(f'valid loss={running_loss:.3f} \\t'\n",
    "              f'valid auc={ auc         :.3f} \\t', end='')\n",
    "\n",
    "        if auc > best_aucs[i_fold]:\n",
    "            best_aucs[i_fold] = auc\n",
    "            torch.save(net.state_dict(), f'../models/{i_fold}.pt')\n",
    "            print(f'model saved!', end='')\n",
    "            stop_cnt = 0\n",
    "        else:\n",
    "            stop_cnt += 1\n",
    "            if stop_cnt > PATIENCE:\n",
    "                print()\n",
    "                break\n",
    "        print()"
   ],
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "execution_count": 8,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fold 0 started!\n",
      "100%|██████████| 10875077/10875077 [00:10<00:00, 1042811.71it/s]\n",
      "10875077it [00:05, 2091441.78it/s]\n",
      "100%|██████████| 3017489/3017489 [00:02<00:00, 1050630.61it/s]\n",
      "3017489it [00:01, 2115664.04it/s]\n",
      "Epoch 1 \ttrain loss=0.633 \ttrain auc=0.565 \tvalid loss=0.637 \tvalid auc=0.573 \tmodel saved!\n",
      "Epoch 2 \ttrain loss=0.576 \ttrain auc=0.723 \tvalid loss=0.611 \tvalid auc=0.657 \tmodel saved!\n",
      "Epoch 3 \ttrain loss=0.554 \ttrain auc=0.741 \tvalid loss=0.625 \tvalid auc=0.661 \tmodel saved!\n",
      "Epoch 4 \ttrain loss=0.537 \ttrain auc=0.761 \tvalid loss=0.626 \tvalid auc=0.660 \t\n",
      "Epoch 5 \ttrain loss=0.522 \ttrain auc=0.771 \tvalid loss=0.615 \tvalid auc=0.673 \tmodel saved!\n",
      "Epoch 6 \ttrain loss=0.514 \ttrain auc=0.777 \tvalid loss=0.617 \tvalid auc=0.677 \tmodel saved!\n",
      "Epoch 7 \ttrain loss=0.505 \ttrain auc=0.785 \tvalid loss=0.613 \tvalid auc=0.683 \tmodel saved!\n",
      "Epoch 8 \ttrain loss=0.500 \ttrain auc=0.788 \tvalid loss=0.614 \tvalid auc=0.675 \t\n",
      "Epoch 9 \ttrain loss=0.497 \ttrain auc=0.792 \tvalid loss=0.618 \tvalid auc=0.678 \t\n",
      "Epoch 10 \ttrain loss=0.498 \ttrain auc=0.791 \tvalid loss=0.605 \tvalid auc=0.687 \tmodel saved!\n",
      "Epoch 11 \ttrain loss=0.496 \ttrain auc=0.793 \tvalid loss=0.606 \tvalid auc=0.692 \tmodel saved!\n",
      "Epoch 12 \ttrain loss=0.490 \ttrain auc=0.798 \tvalid loss=0.626 \tvalid auc=0.680 \t\n",
      "Epoch 13 \ttrain loss=0.485 \ttrain auc=0.803 \tvalid loss=0.630 \tvalid auc=0.685 \t\n",
      "Epoch 14 \ttrain loss=0.483 \ttrain auc=0.804 \tvalid loss=0.623 \tvalid auc=0.686 \t\n",
      "Epoch 15 \ttrain loss=0.480 \ttrain auc=0.806 \tvalid loss=0.619 \tvalid auc=0.688 \t\n",
      "Epoch 16 \ttrain loss=0.481 \ttrain auc=0.805 \tvalid loss=0.618 \tvalid auc=0.685 \t\n",
      "Epoch 17 \ttrain loss=0.477 \ttrain auc=0.808 \tvalid loss=0.612 \tvalid auc=0.698 \tmodel saved!\n",
      "Epoch 18 \ttrain loss=0.476 \ttrain auc=0.809 \tvalid loss=0.623 \tvalid auc=0.686 \t\n",
      "Epoch 19 \ttrain loss=0.473 \ttrain auc=0.811 \tvalid loss=0.601 \tvalid auc=0.701 \tmodel saved!\n",
      "Epoch 20 \ttrain loss=0.469 \ttrain auc=0.813 \tvalid loss=0.611 \tvalid auc=0.693 \t\n",
      "Epoch 21 \ttrain loss=0.468 \ttrain auc=0.814 \tvalid loss=0.634 \tvalid auc=0.687 \t\n",
      "Epoch 22 \ttrain loss=0.464 \ttrain auc=0.817 \tvalid loss=0.635 \tvalid auc=0.684 \t\n",
      "Epoch 23 \ttrain loss=0.463 \ttrain auc=0.819 \tvalid loss=0.632 \tvalid auc=0.683 \t\n",
      "Epoch 24 \ttrain loss=0.461 \ttrain auc=0.821 \tvalid loss=0.630 \tvalid auc=0.688 \t\n",
      "Epoch 25 \ttrain loss=0.459 \ttrain auc=0.823 \tvalid loss=0.623 \tvalid auc=0.688 \t\n",
      "Epoch 26 \ttrain loss=0.453 \ttrain auc=0.825 \tvalid loss=0.632 \tvalid auc=0.680 \t\n",
      "Epoch 27 \ttrain loss=0.455 \ttrain auc=0.826 \tvalid loss=0.640 \tvalid auc=0.684 \t\n",
      "Epoch 28 \ttrain loss=0.453 \ttrain auc=0.825 \tvalid loss=0.630 \tvalid auc=0.685 \t\n",
      "Epoch 29 \ttrain loss=0.448 \ttrain auc=0.831 \tvalid loss=0.641 \tvalid auc=0.678 \t\n",
      "Epoch 30 \ttrain loss=0.450 \ttrain auc=0.828 \tvalid loss=0.635 \tvalid auc=0.675 \t\n",
      "Epoch 31 \ttrain loss=0.449 \ttrain auc=0.829 \tvalid loss=0.630 \tvalid auc=0.680 \t\n",
      "Epoch 32 \ttrain loss=0.448 \ttrain auc=0.830 \tvalid loss=0.649 \tvalid auc=0.677 \t\n",
      "Epoch 33 \ttrain loss=0.442 \ttrain auc=0.834 \tvalid loss=0.640 \tvalid auc=0.677 \t\n",
      "Epoch 34 \ttrain loss=0.441 \ttrain auc=0.833 \tvalid loss=0.656 \tvalid auc=0.670 \t\n",
      "Epoch 35 \ttrain loss=0.439 \ttrain auc=0.835 \tvalid loss=0.652 \tvalid auc=0.659 \t\n",
      "Fold 1 started!\n",
      "100%|██████████| 10412313/10412313 [00:10<00:00, 1022222.17it/s]\n",
      "10412313it [00:04, 2141219.45it/s]\n",
      "100%|██████████| 3557808/3557808 [00:03<00:00, 1055389.46it/s]\n",
      "3557808it [00:01, 2119125.56it/s]\n",
      "Epoch 1 \ttrain loss=0.639 \ttrain auc=0.547 \tvalid loss=0.637 \tvalid auc=0.541 \tmodel saved!\n",
      "Epoch 2 \ttrain loss=0.581 \ttrain auc=0.720 \tvalid loss=0.602 \tvalid auc=0.659 \tmodel saved!\n",
      "Epoch 3 \ttrain loss=0.556 \ttrain auc=0.742 \tvalid loss=0.594 \tvalid auc=0.673 \tmodel saved!\n",
      "Epoch 4 \ttrain loss=0.544 \ttrain auc=0.755 \tvalid loss=0.608 \tvalid auc=0.668 \t\n",
      "Epoch 5 \ttrain loss=0.527 \ttrain auc=0.772 \tvalid loss=0.615 \tvalid auc=0.663 \t\n",
      "Epoch 6 \ttrain loss=0.511 \ttrain auc=0.781 \tvalid loss=0.628 \tvalid auc=0.663 \t\n",
      "Epoch 7 \ttrain loss=0.503 \ttrain auc=0.789 \tvalid loss=0.615 \tvalid auc=0.683 \tmodel saved!\n",
      "Epoch 8 \ttrain loss=0.497 \ttrain auc=0.794 \tvalid loss=0.619 \tvalid auc=0.678 \t\n",
      "Epoch 9 \ttrain loss=0.496 \ttrain auc=0.796 \tvalid loss=0.623 \tvalid auc=0.675 \t\n",
      "Epoch 10 \ttrain loss=0.488 \ttrain auc=0.802 \tvalid loss=0.615 \tvalid auc=0.680 \t\n",
      "Epoch 11 \ttrain loss=0.490 \ttrain auc=0.801 \tvalid loss=0.615 \tvalid auc=0.676 \t\n",
      "Epoch 12 \ttrain loss=0.485 \ttrain auc=0.804 \tvalid loss=0.625 \tvalid auc=0.680 \t\n",
      "Epoch 13 \ttrain loss=0.480 \ttrain auc=0.809 \tvalid loss=0.618 \tvalid auc=0.674 \t\n",
      "Epoch 14 \ttrain loss=0.479 \ttrain auc=0.809 \tvalid loss=0.615 \tvalid auc=0.681 \t\n",
      "Epoch 15 \ttrain loss=0.477 \ttrain auc=0.811 \tvalid loss=0.611 \tvalid auc=0.684 \tmodel saved!\n",
      "Epoch 16 \ttrain loss=0.473 \ttrain auc=0.814 \tvalid loss=0.633 \tvalid auc=0.671 \t\n",
      "Epoch 17 \ttrain loss=0.474 \ttrain auc=0.812 \tvalid loss=0.611 \tvalid auc=0.686 \tmodel saved!\n",
      "Epoch 18 \ttrain loss=0.467 \ttrain auc=0.818 \tvalid loss=0.621 \tvalid auc=0.679 \t\n",
      "Epoch 19 \ttrain loss=0.467 \ttrain auc=0.819 \tvalid loss=0.639 \tvalid auc=0.662 \t\n",
      "Epoch 20 \ttrain loss=0.464 \ttrain auc=0.821 \tvalid loss=0.626 \tvalid auc=0.674 \t\n",
      "Epoch 21 \ttrain loss=0.462 \ttrain auc=0.823 \tvalid loss=0.627 \tvalid auc=0.678 \t\n",
      "Epoch 22 \ttrain loss=0.459 \ttrain auc=0.824 \tvalid loss=0.633 \tvalid auc=0.669 \t\n",
      "Epoch 23 \ttrain loss=0.459 \ttrain auc=0.824 \tvalid loss=0.633 \tvalid auc=0.676 \t\n",
      "Epoch 24 \ttrain loss=0.456 \ttrain auc=0.828 \tvalid loss=0.632 \tvalid auc=0.668 \t\n",
      "Epoch 25 \ttrain loss=0.452 \ttrain auc=0.830 \tvalid loss=0.624 \tvalid auc=0.665 \t\n",
      "Epoch 26 \ttrain loss=0.453 \ttrain auc=0.829 \tvalid loss=0.623 \tvalid auc=0.674 \t\n",
      "Epoch 27 \ttrain loss=0.450 \ttrain auc=0.832 \tvalid loss=0.646 \tvalid auc=0.660 \t\n",
      "Epoch 28 \ttrain loss=0.446 \ttrain auc=0.834 \tvalid loss=0.635 \tvalid auc=0.669 \t\n",
      "Epoch 29 \ttrain loss=0.446 \ttrain auc=0.834 \tvalid loss=0.635 \tvalid auc=0.655 \t\n",
      "Epoch 30 \ttrain loss=0.443 \ttrain auc=0.837 \tvalid loss=0.641 \tvalid auc=0.662 \t\n",
      "Epoch 31 \ttrain loss=0.443 \ttrain auc=0.836 \tvalid loss=0.655 \tvalid auc=0.662 \t\n",
      "Epoch 32 \ttrain loss=0.440 \ttrain auc=0.838 \tvalid loss=0.632 \tvalid auc=0.668 \t\n",
      "Epoch 33 \ttrain loss=0.438 \ttrain auc=0.839 \tvalid loss=0.651 \tvalid auc=0.651 \t\n",
      "Fold 2 started!\n",
      "100%|██████████| 10475023/10475023 [00:10<00:00, 1032133.31it/s]\n",
      "10475023it [00:04, 2117384.55it/s]\n",
      "100%|██████████| 3454626/3454626 [00:03<00:00, 1047856.60it/s]\n",
      "3454626it [00:01, 2072908.05it/s]\n",
      "Epoch 1 \ttrain loss=0.638 \ttrain auc=0.547 \tvalid loss=0.648 \tvalid auc=0.512 \tmodel saved!\n",
      "Epoch 2 \ttrain loss=0.578 \ttrain auc=0.724 \tvalid loss=0.617 \tvalid auc=0.641 \tmodel saved!\n",
      "Epoch 3 \ttrain loss=0.554 \ttrain auc=0.741 \tvalid loss=0.621 \tvalid auc=0.648 \tmodel saved!\n",
      "Epoch 4 \ttrain loss=0.540 \ttrain auc=0.758 \tvalid loss=0.633 \tvalid auc=0.652 \tmodel saved!\n",
      "Epoch 5 \ttrain loss=0.528 \ttrain auc=0.770 \tvalid loss=0.622 \tvalid auc=0.659 \tmodel saved!\n",
      "Epoch 6 \ttrain loss=0.511 \ttrain auc=0.781 \tvalid loss=0.634 \tvalid auc=0.660 \tmodel saved!\n",
      "Epoch 7 \ttrain loss=0.508 \ttrain auc=0.783 \tvalid loss=0.653 \tvalid auc=0.650 \t\n",
      "Epoch 8 \ttrain loss=0.502 \ttrain auc=0.787 \tvalid loss=0.625 \tvalid auc=0.665 \tmodel saved!\n",
      "Epoch 9 \ttrain loss=0.496 \ttrain auc=0.794 \tvalid loss=0.644 \tvalid auc=0.657 \t\n",
      "Epoch 10 \ttrain loss=0.493 \ttrain auc=0.799 \tvalid loss=0.631 \tvalid auc=0.668 \tmodel saved!\n",
      "Epoch 11 \ttrain loss=0.491 \ttrain auc=0.799 \tvalid loss=0.628 \tvalid auc=0.664 \t\n",
      "Epoch 12 \ttrain loss=0.488 \ttrain auc=0.800 \tvalid loss=0.653 \tvalid auc=0.662 \t\n",
      "Epoch 13 \ttrain loss=0.483 \ttrain auc=0.805 \tvalid loss=0.636 \tvalid auc=0.665 \t\n",
      "Epoch 14 \ttrain loss=0.483 \ttrain auc=0.805 \tvalid loss=0.633 \tvalid auc=0.672 \tmodel saved!\n",
      "Epoch 15 \ttrain loss=0.476 \ttrain auc=0.809 \tvalid loss=0.648 \tvalid auc=0.675 \tmodel saved!\n",
      "Epoch 16 \ttrain loss=0.477 \ttrain auc=0.809 \tvalid loss=0.625 \tvalid auc=0.674 \t\n",
      "Epoch 17 \ttrain loss=0.472 \ttrain auc=0.814 \tvalid loss=0.625 \tvalid auc=0.684 \tmodel saved!\n",
      "Epoch 18 \ttrain loss=0.473 \ttrain auc=0.812 \tvalid loss=0.639 \tvalid auc=0.664 \t\n",
      "Epoch 19 \ttrain loss=0.469 \ttrain auc=0.815 \tvalid loss=0.618 \tvalid auc=0.686 \tmodel saved!\n",
      "Epoch 20 \ttrain loss=0.469 \ttrain auc=0.815 \tvalid loss=0.623 \tvalid auc=0.678 \t\n",
      "Epoch 21 \ttrain loss=0.466 \ttrain auc=0.818 \tvalid loss=0.634 \tvalid auc=0.672 \t\n",
      "Epoch 22 \ttrain loss=0.463 \ttrain auc=0.821 \tvalid loss=0.623 \tvalid auc=0.683 \t\n",
      "Epoch 23 \ttrain loss=0.461 \ttrain auc=0.822 \tvalid loss=0.650 \tvalid auc=0.665 \t\n",
      "Epoch 24 \ttrain loss=0.460 \ttrain auc=0.822 \tvalid loss=0.622 \tvalid auc=0.684 \t\n",
      "Epoch 25 \ttrain loss=0.457 \ttrain auc=0.824 \tvalid loss=0.632 \tvalid auc=0.675 \t\n",
      "Epoch 26 \ttrain loss=0.456 \ttrain auc=0.823 \tvalid loss=0.648 \tvalid auc=0.665 \t\n",
      "Epoch 27 \ttrain loss=0.450 \ttrain auc=0.830 \tvalid loss=0.641 \tvalid auc=0.669 \t\n",
      "Epoch 28 \ttrain loss=0.450 \ttrain auc=0.830 \tvalid loss=0.659 \tvalid auc=0.661 \t\n",
      "Epoch 29 \ttrain loss=0.451 \ttrain auc=0.827 \tvalid loss=0.656 \tvalid auc=0.660 \t\n",
      "Epoch 30 \ttrain loss=0.446 \ttrain auc=0.833 \tvalid loss=0.650 \tvalid auc=0.669 \t\n",
      "Epoch 31 \ttrain loss=0.446 \ttrain auc=0.833 \tvalid loss=0.652 \tvalid auc=0.662 \t\n",
      "Epoch 32 \ttrain loss=0.442 \ttrain auc=0.834 \tvalid loss=0.679 \tvalid auc=0.650 \t\n",
      "Epoch 33 \ttrain loss=0.443 \ttrain auc=0.834 \tvalid loss=0.669 \tvalid auc=0.660 \t\n",
      "Epoch 34 \ttrain loss=0.441 \ttrain auc=0.836 \tvalid loss=0.656 \tvalid auc=0.662 \t\n",
      "Epoch 35 \ttrain loss=0.439 \ttrain auc=0.838 \tvalid loss=0.661 \tvalid auc=0.655 \t\n",
      "Fold 3 started!\n",
      "100%|██████████| 10534596/10534596 [00:10<00:00, 1034901.47it/s]\n",
      "10534596it [00:04, 2176097.59it/s]\n",
      "100%|██████████| 3270286/3270286 [00:03<00:00, 1032716.97it/s]\n",
      "3270286it [00:01, 2122625.83it/s]\n",
      "Epoch 1 \ttrain loss=0.634 \ttrain auc=0.578 \tvalid loss=0.633 \tvalid auc=0.513 \tmodel saved!\n",
      "Epoch 2 \ttrain loss=0.578 \ttrain auc=0.722 \tvalid loss=0.602 \tvalid auc=0.640 \tmodel saved!\n",
      "Epoch 3 \ttrain loss=0.558 \ttrain auc=0.741 \tvalid loss=0.600 \tvalid auc=0.661 \tmodel saved!\n",
      "Epoch 4 \ttrain loss=0.546 \ttrain auc=0.757 \tvalid loss=0.616 \tvalid auc=0.648 \t\n",
      "Epoch 5 \ttrain loss=0.532 \ttrain auc=0.767 \tvalid loss=0.608 \tvalid auc=0.662 \tmodel saved!\n",
      "Epoch 6 \ttrain loss=0.519 \ttrain auc=0.775 \tvalid loss=0.598 \tvalid auc=0.678 \tmodel saved!\n",
      "Epoch 7 \ttrain loss=0.509 \ttrain auc=0.784 \tvalid loss=0.606 \tvalid auc=0.671 \t\n",
      "Epoch 8 \ttrain loss=0.506 \ttrain auc=0.787 \tvalid loss=0.599 \tvalid auc=0.677 \t\n",
      "Epoch 9 \ttrain loss=0.499 \ttrain auc=0.795 \tvalid loss=0.602 \tvalid auc=0.678 \tmodel saved!\n",
      "Epoch 10 \ttrain loss=0.500 \ttrain auc=0.792 \tvalid loss=0.598 \tvalid auc=0.681 \tmodel saved!\n",
      "Epoch 11 \ttrain loss=0.495 \ttrain auc=0.797 \tvalid loss=0.602 \tvalid auc=0.674 \t\n",
      "Epoch 12 \ttrain loss=0.488 \ttrain auc=0.803 \tvalid loss=0.610 \tvalid auc=0.678 \t\n",
      "Epoch 13 \ttrain loss=0.486 \ttrain auc=0.806 \tvalid loss=0.599 \tvalid auc=0.687 \tmodel saved!\n",
      "Epoch 14 \ttrain loss=0.487 \ttrain auc=0.804 \tvalid loss=0.613 \tvalid auc=0.666 \t\n",
      "Epoch 15 \ttrain loss=0.485 \ttrain auc=0.805 \tvalid loss=0.607 \tvalid auc=0.679 \t\n",
      "Epoch 16 \ttrain loss=0.480 \ttrain auc=0.810 \tvalid loss=0.610 \tvalid auc=0.676 \t\n",
      "Epoch 17 \ttrain loss=0.475 \ttrain auc=0.814 \tvalid loss=0.609 \tvalid auc=0.675 \t\n",
      "Epoch 18 \ttrain loss=0.473 \ttrain auc=0.816 \tvalid loss=0.618 \tvalid auc=0.669 \t\n",
      "Epoch 19 \ttrain loss=0.471 \ttrain auc=0.817 \tvalid loss=0.606 \tvalid auc=0.675 \t\n",
      "Epoch 20 \ttrain loss=0.470 \ttrain auc=0.819 \tvalid loss=0.631 \tvalid auc=0.665 \t\n",
      "Epoch 21 \ttrain loss=0.467 \ttrain auc=0.819 \tvalid loss=0.611 \tvalid auc=0.666 \t\n",
      "Epoch 22 \ttrain loss=0.465 \ttrain auc=0.822 \tvalid loss=0.617 \tvalid auc=0.670 \t\n",
      "Epoch 23 \ttrain loss=0.465 \ttrain auc=0.821 \tvalid loss=0.619 \tvalid auc=0.671 \t\n",
      "Epoch 24 \ttrain loss=0.464 \ttrain auc=0.821 \tvalid loss=0.621 \tvalid auc=0.661 \t\n",
      "Epoch 25 \ttrain loss=0.460 \ttrain auc=0.826 \tvalid loss=0.631 \tvalid auc=0.661 \t\n",
      "Epoch 26 \ttrain loss=0.456 \ttrain auc=0.829 \tvalid loss=0.630 \tvalid auc=0.662 \t\n",
      "Epoch 27 \ttrain loss=0.454 \ttrain auc=0.830 \tvalid loss=0.639 \tvalid auc=0.654 \t\n",
      "Epoch 28 \ttrain loss=0.453 \ttrain auc=0.830 \tvalid loss=0.624 \tvalid auc=0.657 \t\n",
      "Epoch 29 \ttrain loss=0.451 \ttrain auc=0.832 \tvalid loss=0.635 \tvalid auc=0.656 \t\n",
      "Fold 4 started!\n",
      "100%|██████████| 10639319/10639319 [00:10<00:00, 1031626.95it/s]\n",
      "10639319it [00:04, 2179010.20it/s]\n",
      "100%|██████████| 3254454/3254454 [00:03<00:00, 1033103.04it/s]\n",
      "3254454it [00:01, 2107259.80it/s]\n",
      "Epoch 1 \ttrain loss=0.633 \ttrain auc=0.570 \tvalid loss=0.630 \tvalid auc=0.593 \tmodel saved!\n",
      "Epoch 2 \ttrain loss=0.582 \ttrain auc=0.720 \tvalid loss=0.598 \tvalid auc=0.662 \tmodel saved!\n",
      "Epoch 3 \ttrain loss=0.558 \ttrain auc=0.739 \tvalid loss=0.607 \tvalid auc=0.663 \tmodel saved!\n",
      "Epoch 4 \ttrain loss=0.545 \ttrain auc=0.755 \tvalid loss=0.630 \tvalid auc=0.647 \t\n",
      "Epoch 5 \ttrain loss=0.529 \ttrain auc=0.769 \tvalid loss=0.611 \tvalid auc=0.673 \tmodel saved!\n",
      "Epoch 6 \ttrain loss=0.517 \ttrain auc=0.777 \tvalid loss=0.609 \tvalid auc=0.673 \t\n",
      "Epoch 7 \ttrain loss=0.510 \ttrain auc=0.783 \tvalid loss=0.604 \tvalid auc=0.680 \tmodel saved!\n",
      "Epoch 8 \ttrain loss=0.504 \ttrain auc=0.790 \tvalid loss=0.601 \tvalid auc=0.686 \tmodel saved!\n",
      "Epoch 9 \ttrain loss=0.498 \ttrain auc=0.792 \tvalid loss=0.597 \tvalid auc=0.694 \tmodel saved!\n",
      "Epoch 10 \ttrain loss=0.498 \ttrain auc=0.793 \tvalid loss=0.618 \tvalid auc=0.680 \t\n",
      "Epoch 11 \ttrain loss=0.492 \ttrain auc=0.798 \tvalid loss=0.594 \tvalid auc=0.691 \t\n",
      "Epoch 12 \ttrain loss=0.490 \ttrain auc=0.799 \tvalid loss=0.599 \tvalid auc=0.693 \t\n",
      "Epoch 13 \ttrain loss=0.485 \ttrain auc=0.802 \tvalid loss=0.604 \tvalid auc=0.689 \t\n",
      "Epoch 14 \ttrain loss=0.483 \ttrain auc=0.804 \tvalid loss=0.607 \tvalid auc=0.690 \t\n",
      "Epoch 15 \ttrain loss=0.477 \ttrain auc=0.810 \tvalid loss=0.601 \tvalid auc=0.690 \t\n",
      "Epoch 16 \ttrain loss=0.481 \ttrain auc=0.806 \tvalid loss=0.613 \tvalid auc=0.682 \t\n",
      "Epoch 17 \ttrain loss=0.474 \ttrain auc=0.812 \tvalid loss=0.605 \tvalid auc=0.689 \t\n",
      "Epoch 18 \ttrain loss=0.475 \ttrain auc=0.811 \tvalid loss=0.614 \tvalid auc=0.685 \t\n",
      "Epoch 19 \ttrain loss=0.472 \ttrain auc=0.813 \tvalid loss=0.616 \tvalid auc=0.687 \t\n",
      "Epoch 20 \ttrain loss=0.473 \ttrain auc=0.813 \tvalid loss=0.618 \tvalid auc=0.680 \t\n",
      "Epoch 21 \ttrain loss=0.469 \ttrain auc=0.816 \tvalid loss=0.623 \tvalid auc=0.682 \t\n",
      "Epoch 22 \ttrain loss=0.464 \ttrain auc=0.819 \tvalid loss=0.635 \tvalid auc=0.671 \t\n",
      "Epoch 23 \ttrain loss=0.466 \ttrain auc=0.819 \tvalid loss=0.617 \tvalid auc=0.678 \t\n",
      "Epoch 24 \ttrain loss=0.462 \ttrain auc=0.821 \tvalid loss=0.614 \tvalid auc=0.690 \t\n",
      "Epoch 25 \ttrain loss=0.462 \ttrain auc=0.822 \tvalid loss=0.621 \tvalid auc=0.678 \t\n"
     ]
    }
   ]
  },
  {
   "source": [
    "# Make a Submission File"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "testset = Dataset(testdata)\n",
    "testloader = DataLoader(testset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "net = Net(INPUT_NUM)\n",
    "net.to(device) \n",
    "\n",
    "votes = np.zeros(len(testloader.dataset))\n",
    "\n",
    "for i in range(k_fold.get_n_splits()):\n",
    "    net.load_state_dict(torch.load(f'../models/{i}.pt'))\n",
    "\n",
    "    saved_outputs = []\n",
    "\n",
    "    for i, data in enumerate(testloader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        saved_outputs += outputs.squeeze().tolist()\n",
    "\n",
    "    votes += np.array(saved_outputs)\n",
    "\n",
    "votes = votes / k_fold.get_n_splits()\n",
    "\n",
    "sample_submission = pd.read_csv(os.path.join(PATH, 'sample_submission.csv'))\n",
    "sample_submission['problem'] = votes\n",
    "sample_submission.to_csv('../submission.csv', index=False)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 9,
   "outputs": []
  },
  {
   "source": [
    "# Print the AUC Score"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.6908294363003846"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "cv_auc = sum(best_aucs) / len(best_aucs)\n",
    "cv_auc"
   ]
  }
 ]
}